Script started on 2021-04-22 14:07:43+0900
(base) ]0;hs402@AIHA-Server1: ~/nlp-architect/skt1_scripts[01;32mhs402@AIHA-Server1[00m:[01;34m~/nlp-architect/skt1_scripts[00m$ 
[K(base) ]0;hs402@AIHA-Server1: ~/nlp-architect/skt1_scripts[01;32mhs402@AIHA-Server1[00m:[01;34m~/nlp-architect/skt1_scripts[00m$ conda actiavet[K[K[K[Kvate nlp
(nlp) ]0;hs402@AIHA-Server1: ~/nlp-architect/skt1_scripts[01;32mhs402@AIHA-Server1[00m:[01;34m~/nlp-architect/skt1_scripts[00m$ . tr_test.sh
2021-04-22 14:10:11,360 INFO PyTorch version 1.4.0 available.
/home/hs402/anaconda3/envs/nlp/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.
  warnings.warn(msg)
2021-04-22 14:10:13,930 INFO Model name '../../Qbert_model' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../../Qbert_model' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-04-22 14:10:13,931 INFO Didn't find file ../../Qbert_model/added_tokens.json. We won't load it.
2021-04-22 14:10:13,931 INFO Didn't find file ../../Qbert_model/special_tokens_map.json. We won't load it.
2021-04-22 14:10:13,931 INFO Didn't find file ../../Qbert_model/tokenizer_config.json. We won't load it.
2021-04-22 14:10:13,931 INFO loading file ../../Qbert_model/vocab.txt
2021-04-22 14:10:13,931 INFO loading file None
2021-04-22 14:10:13,931 INFO loading file None
2021-04-22 14:10:13,931 INFO loading file None
2021-04-22 14:10:13,962 INFO loading configuration file ../../Qbert_model/config.json
2021-04-22 14:10:13,962 INFO Model config QuantizedBertConfig {
  "architectures": null,
  "attention_key": {
    "mode": "ema"
  },
  "attention_output": {
    "mode": "ema",
    "requantize_output": false
  },
  "attention_probs_dropout_prob": 0.1,
  "attention_query": {
    "mode": "ema"
  },
  "attention_value": {
    "mode": "ema",
    "requantize_output": false
  },
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "ffn_intermediate": {
    "mode": "ema",
    "requantize_output": false
  },
  "ffn_output": {
    "mode": "ema",
    "requantize_output": false
  },
  "finetuning_task": null,
  "head": {
    "mode": "ema",
    "requantize_output": false,
    "start_step": 200
  },
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler": {
    "mode": "ema",
    "requantize_output": false
  },
  "position_embeddings": {
    "mode": "ema"
  },
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "token_type_embeddings": {
    "mode": "none"
  },
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522,
  "word_embeddings": {
    "mode": "ema"
  }
}

2021-04-22 14:10:13,964 INFO loading weights file ../../Qbert_model/pytorch_model.bin
2021-04-22 14:10:17,037 INFO Weights of QuantizedBertForSequenceClassification not initialized from pretrained model: ['bert.embeddings.word_embeddings._step', 'bert.embeddings.position_embeddings._step', 'bert.embeddings.token_type_embeddings._step', 'bert.encoder.layer.0.attention.self._step', 'bert.encoder.layer.0.attention.self.COM2_thresh', 'bert.encoder.layer.0.attention.self.COM3_thresh', 'bert.encoder.layer.0.attention.self.COM4_thresh', 'bert.encoder.layer.0.attention.self.query._step', 'bert.encoder.layer.0.attention.self.query.input_thresh', 'bert.encoder.layer.0.attention.self.query.output_thresh', 'bert.encoder.layer.0.attention.self.key._step', 'bert.encoder.layer.0.attention.self.key.input_thresh', 'bert.encoder.layer.0.attention.self.key.output_thresh', 'bert.encoder.layer.0.attention.self.value._step', 'bert.encoder.layer.0.attention.self.value.input_thresh', 'bert.encoder.layer.0.attention.output.dense._step', 'bert.encoder.layer.0.attention.output.dense.input_thresh', 'bert.encoder.layer.0.attention.output.dense.output_thresh', 'bert.encoder.layer.0.intermediate.dense._step', 'bert.encoder.layer.0.intermediate.dense.input_thresh', 'bert.encoder.layer.0.output.dense._step', 'bert.encoder.layer.0.output.dense.input_thresh', 'bert.encoder.layer.1.attention.self._step', 'bert.encoder.layer.1.attention.self.COM2_thresh', 'bert.encoder.layer.1.attention.self.COM3_thresh', 'bert.encoder.layer.1.attention.self.COM4_thresh', 'bert.encoder.layer.1.attention.self.query._step', 'bert.encoder.layer.1.attention.self.query.input_thresh', 'bert.encoder.layer.1.attention.self.query.output_thresh', 'bert.encoder.layer.1.attention.self.key._step', 'bert.encoder.layer.1.attention.self.key.input_thresh', 'bert.encoder.layer.1.attention.self.key.output_thresh', 'bert.encoder.layer.1.attention.self.value._step', 'bert.encoder.layer.1.attention.self.value.input_thresh', 'bert.encoder.layer.1.attention.output.dense._step', 'bert.encoder.layer.1.attention.output.dense.input_thresh', 'bert.encoder.layer.1.attention.output.dense.output_thresh', 'bert.encoder.layer.1.intermediate.dense._step', 'bert.encoder.layer.1.intermediate.dense.input_thresh', 'bert.encoder.layer.1.output.dense._step', 'bert.encoder.layer.1.output.dense.input_thresh', 'bert.encoder.layer.2.attention.self._step', 'bert.encoder.layer.2.attention.self.COM2_thresh', 'bert.encoder.layer.2.attention.self.COM3_thresh', 'bert.encoder.layer.2.attention.self.COM4_thresh', 'bert.encoder.layer.2.attention.self.query._step', 'bert.encoder.layer.2.attention.self.query.input_thresh', 'bert.encoder.layer.2.attention.self.query.output_thresh', 'bert.encoder.layer.2.attention.self.key._step', 'bert.encoder.layer.2.attention.self.key.input_thresh', 'bert.encoder.layer.2.attention.self.key.output_thresh', 'bert.encoder.layer.2.attention.self.value._step', 'bert.encoder.layer.2.attention.self.value.input_thresh', 'bert.encoder.layer.2.attention.output.dense._step', 'bert.encoder.layer.2.attention.output.dense.input_thresh', 'bert.encoder.layer.2.attention.output.dense.output_thresh', 'bert.encoder.layer.2.intermediate.dense._step', 'bert.encoder.layer.2.intermediate.dense.input_thresh', 'bert.encoder.layer.2.output.dense._step', 'bert.encoder.layer.2.output.dense.input_thresh', 'bert.encoder.layer.3.attention.self._step', 'bert.encoder.layer.3.attention.self.COM2_thresh', 'bert.encoder.layer.3.attention.self.COM3_thresh', 'bert.encoder.layer.3.attention.self.COM4_thresh', 'bert.encoder.layer.3.attention.self.query._step', 'bert.encoder.layer.3.attention.self.query.input_thresh', 'bert.encoder.layer.3.attention.self.query.output_thresh', 'bert.encoder.layer.3.attention.self.key._step', 'bert.encoder.layer.3.attention.self.key.input_thresh', 'bert.encoder.layer.3.attention.self.key.output_thresh', 'bert.encoder.layer.3.attention.self.value._step', 'bert.encoder.layer.3.attention.self.value.input_thresh', 'bert.encoder.layer.3.attention.output.dense._step', 'bert.encoder.layer.3.attention.output.dense.input_thresh', 'bert.encoder.layer.3.attention.output.dense.output_thresh', 'bert.encoder.layer.3.intermediate.dense._step', 'bert.encoder.layer.3.intermediate.dense.input_thresh', 'bert.encoder.layer.3.output.dense._step', 'bert.encoder.layer.3.output.dense.input_thresh', 'bert.encoder.layer.4.attention.self._step', 'bert.encoder.layer.4.attention.self.COM2_thresh', 'bert.encoder.layer.4.attention.self.COM3_thresh', 'bert.encoder.layer.4.attention.self.COM4_thresh', 'bert.encoder.layer.4.attention.self.query._step', 'bert.encoder.layer.4.attention.self.query.input_thresh', 'bert.encoder.layer.4.attention.self.query.output_thresh', 'bert.encoder.layer.4.attention.self.key._step', 'bert.encoder.layer.4.attention.self.key.input_thresh', 'bert.encoder.layer.4.attention.self.key.output_thresh', 'bert.encoder.layer.4.attention.self.value._step', 'bert.encoder.layer.4.attention.self.value.input_thresh', 'bert.encoder.layer.4.attention.output.dense._step', 'bert.encoder.layer.4.attention.output.dense.input_thresh', 'bert.encoder.layer.4.attention.output.dense.output_thresh', 'bert.encoder.layer.4.intermediate.dense._step', 'bert.encoder.layer.4.intermediate.dense.input_thresh', 'bert.encoder.layer.4.output.dense._step', 'bert.encoder.layer.4.output.dense.input_thresh', 'bert.encoder.layer.5.attention.self._step', 'bert.encoder.layer.5.attention.self.COM2_thresh', 'bert.encoder.layer.5.attention.self.COM3_thresh', 'bert.encoder.layer.5.attention.self.COM4_thresh', 'bert.encoder.layer.5.attention.self.query._step', 'bert.encoder.layer.5.attention.self.query.input_thresh', 'bert.encoder.layer.5.attention.self.query.output_thresh', 'bert.encoder.layer.5.attention.self.key._step', 'bert.encoder.layer.5.attention.self.key.input_thresh', 'bert.encoder.layer.5.attention.self.key.output_thresh', 'bert.encoder.layer.5.attention.self.value._step', 'bert.encoder.layer.5.attention.self.value.input_thresh', 'bert.encoder.layer.5.attention.output.dense._step', 'bert.encoder.layer.5.attention.output.dense.input_thresh', 'bert.encoder.layer.5.attention.output.dense.output_thresh', 'bert.encoder.layer.5.intermediate.dense._step', 'bert.encoder.layer.5.intermediate.dense.input_thresh', 'bert.encoder.layer.5.output.dense._step', 'bert.encoder.layer.5.output.dense.input_thresh', 'bert.encoder.layer.6.attention.self._step', 'bert.encoder.layer.6.attention.self.COM2_thresh', 'bert.encoder.layer.6.attention.self.COM3_thresh', 'bert.encoder.layer.6.attention.self.COM4_thresh', 'bert.encoder.layer.6.attention.self.query._step', 'bert.encoder.layer.6.attention.self.query.input_thresh', 'bert.encoder.layer.6.attention.self.query.output_thresh', 'bert.encoder.layer.6.attention.self.key._step', 'bert.encoder.layer.6.attention.self.key.input_thresh', 'bert.encoder.layer.6.attention.self.key.output_thresh', 'bert.encoder.layer.6.attention.self.value._step', 'bert.encoder.layer.6.attention.self.value.input_thresh', 'bert.encoder.layer.6.attention.output.dense._step', 'bert.encoder.layer.6.attention.output.dense.input_thresh', 'bert.encoder.layer.6.attention.output.dense.output_thresh', 'bert.encoder.layer.6.intermediate.dense._step', 'bert.encoder.layer.6.intermediate.dense.input_thresh', 'bert.encoder.layer.6.output.dense._step', 'bert.encoder.layer.6.output.dense.input_thresh', 'bert.encoder.layer.7.attention.self._step', 'bert.encoder.layer.7.attention.self.COM2_thresh', 'bert.encoder.layer.7.attention.self.COM3_thresh', 'bert.encoder.layer.7.attention.self.COM4_thresh', 'bert.encoder.layer.7.attention.self.query._step', 'bert.encoder.layer.7.attention.self.query.input_thresh', 'bert.encoder.layer.7.attention.self.query.output_thresh', 'bert.encoder.layer.7.attention.self.key._step', 'bert.encoder.layer.7.attention.self.key.input_thresh', 'bert.encoder.layer.7.attention.self.key.output_thresh', 'bert.encoder.layer.7.attention.self.value._step', 'bert.encoder.layer.7.attention.self.value.input_thresh', 'bert.encoder.layer.7.attention.output.dense._step', 'bert.encoder.layer.7.attention.output.dense.input_thresh', 'bert.encoder.layer.7.attention.output.dense.output_thresh', 'bert.encoder.layer.7.intermediate.dense._step', 'bert.encoder.layer.7.intermediate.dense.input_thresh', 'bert.encoder.layer.7.output.dense._step', 'bert.encoder.layer.7.output.dense.input_thresh', 'bert.encoder.layer.8.attention.self._step', 'bert.encoder.layer.8.attention.self.COM2_thresh', 'bert.encoder.layer.8.attention.self.COM3_thresh', 'bert.encoder.layer.8.attention.self.COM4_thresh', 'bert.encoder.layer.8.attention.self.query._step', 'bert.encoder.layer.8.attention.self.query.input_thresh', 'bert.encoder.layer.8.attention.self.query.output_thresh', 'bert.encoder.layer.8.attention.self.key._step', 'bert.encoder.layer.8.attention.self.key.input_thresh', 'bert.encoder.layer.8.attention.self.key.output_thresh', 'bert.encoder.layer.8.attention.self.value._step', 'bert.encoder.layer.8.attention.self.value.input_thresh', 'bert.encoder.layer.8.attention.output.dense._step', 'bert.encoder.layer.8.attention.output.dense.input_thresh', 'bert.encoder.layer.8.attention.output.dense.output_thresh', 'bert.encoder.layer.8.intermediate.dense._step', 'bert.encoder.layer.8.intermediate.dense.input_thresh', 'bert.encoder.layer.8.output.dense._step', 'bert.encoder.layer.8.output.dense.input_thresh', 'bert.encoder.layer.9.attention.self._step', 'bert.encoder.layer.9.attention.self.COM2_thresh', 'bert.encoder.layer.9.attention.self.COM3_thresh', 'bert.encoder.layer.9.attention.self.COM4_thresh', 'bert.encoder.layer.9.attention.self.query._step', 'bert.encoder.layer.9.attention.self.query.input_thresh', 'bert.encoder.layer.9.attention.self.query.output_thresh', 'bert.encoder.layer.9.attention.self.key._step', 'bert.encoder.layer.9.attention.self.key.input_thresh', 'bert.encoder.layer.9.attention.self.key.output_thresh', 'bert.encoder.layer.9.attention.self.value._step', 'bert.encoder.layer.9.attention.self.value.input_thresh', 'bert.encoder.layer.9.attention.output.dense._step', 'bert.encoder.layer.9.attention.output.dense.input_thresh', 'bert.encoder.layer.9.attention.output.dense.output_thresh', 'bert.encoder.layer.9.intermediate.dense._step', 'bert.encoder.layer.9.intermediate.dense.input_thresh', 'bert.encoder.layer.9.output.dense._step', 'bert.encoder.layer.9.output.dense.input_thresh', 'bert.encoder.layer.10.attention.self._step', 'bert.encoder.layer.10.attention.self.COM2_thresh', 'bert.encoder.layer.10.attention.self.COM3_thresh', 'bert.encoder.layer.10.attention.self.COM4_thresh', 'bert.encoder.layer.10.attention.self.query._step', 'bert.encoder.layer.10.attention.self.query.input_thresh', 'bert.encoder.layer.10.attention.self.query.output_thresh', 'bert.encoder.layer.10.attention.self.key._step', 'bert.encoder.layer.10.attention.self.key.input_thresh', 'bert.encoder.layer.10.attention.self.key.output_thresh', 'bert.encoder.layer.10.attention.self.value._step', 'bert.encoder.layer.10.attention.self.value.input_thresh', 'bert.encoder.layer.10.attention.output.dense._step', 'bert.encoder.layer.10.attention.output.dense.input_thresh', 'bert.encoder.layer.10.attention.output.dense.output_thresh', 'bert.encoder.layer.10.intermediate.dense._step', 'bert.encoder.layer.10.intermediate.dense.input_thresh', 'bert.encoder.layer.10.output.dense._step', 'bert.encoder.layer.10.output.dense.input_thresh', 'bert.encoder.layer.11.attention.self._step', 'bert.encoder.layer.11.attention.self.COM2_thresh', 'bert.encoder.layer.11.attention.self.COM3_thresh', 'bert.encoder.layer.11.attention.self.COM4_thresh', 'bert.encoder.layer.11.attention.self.query._step', 'bert.encoder.layer.11.attention.self.query.input_thresh', 'bert.encoder.layer.11.attention.self.query.output_thresh', 'bert.encoder.layer.11.attention.self.key._step', 'bert.encoder.layer.11.attention.self.key.input_thresh', 'bert.encoder.layer.11.attention.self.key.output_thresh', 'bert.encoder.layer.11.attention.self.value._step', 'bert.encoder.layer.11.attention.self.value.input_thresh', 'bert.encoder.layer.11.attention.output.dense._step', 'bert.encoder.layer.11.attention.output.dense.input_thresh', 'bert.encoder.layer.11.attention.output.dense.output_thresh', 'bert.encoder.layer.11.intermediate.dense._step', 'bert.encoder.layer.11.intermediate.dense.input_thresh', 'bert.encoder.layer.11.output.dense._step', 'bert.encoder.layer.11.output.dense.input_thresh', 'bert.pooler.dense._step', 'bert.pooler.dense.input_thresh', 'classifier.weight', 'classifier.bias', 'classifier._step', 'classifier.input_thresh']
2021-04-22 14:10:17,037 INFO Weights from pretrained model not used in QuantizedBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
Traceback (most recent call last):
  File "/home/hs402/anaconda3/envs/nlp/bin/nlp-train", line 7, in <module>
    exec(compile(f.read(), __file__, 'exec'))
  File "/home/hs402/nlp-architect/nlp_architect/nlp-train", line 5, in <module>
    nlp_train_cli()
  File "/home/hs402/nlp-architect/nlp_architect/cli/__init__.py", line 45, in nlp_train_cli
    args.func(args)
  File "/home/hs402/nlp-architect/nlp_architect/procedures/transformers/glue.py", line 47, in run_procedure
    do_training(args)
  File "/home/hs402/nlp-architect/nlp_architect/procedures/transformers/glue.py", line 179, in do_training
    freeze_bert=args.freeze_bert
  File "/home/hs402/nlp-architect/nlp_architect/models/transformers/sequence_classification.py", line 113, in __init__
    print('name : ' + name + ' / class: ' + module.__class__)
TypeError: can only concatenate str (not "type") to str
(nlp) ]0;hs402@AIHA-Server1: ~/nlp-architect/skt1_scripts[01;32mhs402@AIHA-Server1[00m:[01;34m~/nlp-architect/skt1_scripts[00m$ cl[K[K. tr_test.shconda activate nlp[6P. tr_test.sh
2021-04-22 14:11:42,793 INFO PyTorch version 1.4.0 available.
/home/hs402/anaconda3/envs/nlp/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.
  warnings.warn(msg)
2021-04-22 14:11:45,402 INFO Model name '../../Qbert_model' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../../Qbert_model' is a path, a model identifier, or url to a directory containing tokenizer files.
2021-04-22 14:11:45,403 INFO Didn't find file ../../Qbert_model/added_tokens.json. We won't load it.
2021-04-22 14:11:45,403 INFO Didn't find file ../../Qbert_model/special_tokens_map.json. We won't load it.
2021-04-22 14:11:45,403 INFO Didn't find file ../../Qbert_model/tokenizer_config.json. We won't load it.
2021-04-22 14:11:45,403 INFO loading file ../../Qbert_model/vocab.txt
2021-04-22 14:11:45,403 INFO loading file None
2021-04-22 14:11:45,403 INFO loading file None
2021-04-22 14:11:45,403 INFO loading file None
2021-04-22 14:11:45,445 INFO loading configuration file ../../Qbert_model/config.json
2021-04-22 14:11:45,446 INFO Model config QuantizedBertConfig {
  "architectures": null,
  "attention_key": {
    "mode": "ema"
  },
  "attention_output": {
    "mode": "ema",
    "requantize_output": false
  },
  "attention_probs_dropout_prob": 0.1,
  "attention_query": {
    "mode": "ema"
  },
  "attention_value": {
    "mode": "ema",
    "requantize_output": false
  },
  "bos_token_id": 0,
  "do_sample": false,
  "eos_token_ids": 0,
  "ffn_intermediate": {
    "mode": "ema",
    "requantize_output": false
  },
  "ffn_output": {
    "mode": "ema",
    "requantize_output": false
  },
  "finetuning_task": null,
  "head": {
    "mode": "ema",
    "requantize_output": false,
    "start_step": 200
  },
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "id2label": {
    "0": "LABEL_0",
    "1": "LABEL_1"
  },
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "is_decoder": false,
  "label2id": {
    "LABEL_0": 0,
    "LABEL_1": 1
  },
  "layer_norm_eps": 1e-12,
  "length_penalty": 1.0,
  "max_length": 20,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_beams": 1,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "num_return_sequences": 1,
  "output_attentions": true,
  "output_hidden_states": false,
  "output_past": true,
  "pad_token_id": 0,
  "pooler": {
    "mode": "ema",
    "requantize_output": false
  },
  "position_embeddings": {
    "mode": "ema"
  },
  "pruned_heads": {},
  "repetition_penalty": 1.0,
  "temperature": 1.0,
  "token_type_embeddings": {
    "mode": "none"
  },
  "top_k": 50,
  "top_p": 1.0,
  "torchscript": false,
  "type_vocab_size": 2,
  "use_bfloat16": false,
  "vocab_size": 30522,
  "word_embeddings": {
    "mode": "ema"
  }
}

2021-04-22 14:11:45,448 INFO loading weights file ../../Qbert_model/pytorch_model.bin
2021-04-22 14:11:48,646 INFO Weights of QuantizedBertForSequenceClassification not initialized from pretrained model: ['bert.embeddings.word_embeddings._step', 'bert.embeddings.position_embeddings._step', 'bert.embeddings.token_type_embeddings._step', 'bert.encoder.layer.0.attention.self._step', 'bert.encoder.layer.0.attention.self.COM2_thresh', 'bert.encoder.layer.0.attention.self.COM3_thresh', 'bert.encoder.layer.0.attention.self.COM4_thresh', 'bert.encoder.layer.0.attention.self.query._step', 'bert.encoder.layer.0.attention.self.query.input_thresh', 'bert.encoder.layer.0.attention.self.query.output_thresh', 'bert.encoder.layer.0.attention.self.key._step', 'bert.encoder.layer.0.attention.self.key.input_thresh', 'bert.encoder.layer.0.attention.self.key.output_thresh', 'bert.encoder.layer.0.attention.self.value._step', 'bert.encoder.layer.0.attention.self.value.input_thresh', 'bert.encoder.layer.0.attention.output.dense._step', 'bert.encoder.layer.0.attention.output.dense.input_thresh', 'bert.encoder.layer.0.attention.output.dense.output_thresh', 'bert.encoder.layer.0.intermediate.dense._step', 'bert.encoder.layer.0.intermediate.dense.input_thresh', 'bert.encoder.layer.0.output.dense._step', 'bert.encoder.layer.0.output.dense.input_thresh', 'bert.encoder.layer.1.attention.self._step', 'bert.encoder.layer.1.attention.self.COM2_thresh', 'bert.encoder.layer.1.attention.self.COM3_thresh', 'bert.encoder.layer.1.attention.self.COM4_thresh', 'bert.encoder.layer.1.attention.self.query._step', 'bert.encoder.layer.1.attention.self.query.input_thresh', 'bert.encoder.layer.1.attention.self.query.output_thresh', 'bert.encoder.layer.1.attention.self.key._step', 'bert.encoder.layer.1.attention.self.key.input_thresh', 'bert.encoder.layer.1.attention.self.key.output_thresh', 'bert.encoder.layer.1.attention.self.value._step', 'bert.encoder.layer.1.attention.self.value.input_thresh', 'bert.encoder.layer.1.attention.output.dense._step', 'bert.encoder.layer.1.attention.output.dense.input_thresh', 'bert.encoder.layer.1.attention.output.dense.output_thresh', 'bert.encoder.layer.1.intermediate.dense._step', 'bert.encoder.layer.1.intermediate.dense.input_thresh', 'bert.encoder.layer.1.output.dense._step', 'bert.encoder.layer.1.output.dense.input_thresh', 'bert.encoder.layer.2.attention.self._step', 'bert.encoder.layer.2.attention.self.COM2_thresh', 'bert.encoder.layer.2.attention.self.COM3_thresh', 'bert.encoder.layer.2.attention.self.COM4_thresh', 'bert.encoder.layer.2.attention.self.query._step', 'bert.encoder.layer.2.attention.self.query.input_thresh', 'bert.encoder.layer.2.attention.self.query.output_thresh', 'bert.encoder.layer.2.attention.self.key._step', 'bert.encoder.layer.2.attention.self.key.input_thresh', 'bert.encoder.layer.2.attention.self.key.output_thresh', 'bert.encoder.layer.2.attention.self.value._step', 'bert.encoder.layer.2.attention.self.value.input_thresh', 'bert.encoder.layer.2.attention.output.dense._step', 'bert.encoder.layer.2.attention.output.dense.input_thresh', 'bert.encoder.layer.2.attention.output.dense.output_thresh', 'bert.encoder.layer.2.intermediate.dense._step', 'bert.encoder.layer.2.intermediate.dense.input_thresh', 'bert.encoder.layer.2.output.dense._step', 'bert.encoder.layer.2.output.dense.input_thresh', 'bert.encoder.layer.3.attention.self._step', 'bert.encoder.layer.3.attention.self.COM2_thresh', 'bert.encoder.layer.3.attention.self.COM3_thresh', 'bert.encoder.layer.3.attention.self.COM4_thresh', 'bert.encoder.layer.3.attention.self.query._step', 'bert.encoder.layer.3.attention.self.query.input_thresh', 'bert.encoder.layer.3.attention.self.query.output_thresh', 'bert.encoder.layer.3.attention.self.key._step', 'bert.encoder.layer.3.attention.self.key.input_thresh', 'bert.encoder.layer.3.attention.self.key.output_thresh', 'bert.encoder.layer.3.attention.self.value._step', 'bert.encoder.layer.3.attention.self.value.input_thresh', 'bert.encoder.layer.3.attention.output.dense._step', 'bert.encoder.layer.3.attention.output.dense.input_thresh', 'bert.encoder.layer.3.attention.output.dense.output_thresh', 'bert.encoder.layer.3.intermediate.dense._step', 'bert.encoder.layer.3.intermediate.dense.input_thresh', 'bert.encoder.layer.3.output.dense._step', 'bert.encoder.layer.3.output.dense.input_thresh', 'bert.encoder.layer.4.attention.self._step', 'bert.encoder.layer.4.attention.self.COM2_thresh', 'bert.encoder.layer.4.attention.self.COM3_thresh', 'bert.encoder.layer.4.attention.self.COM4_thresh', 'bert.encoder.layer.4.attention.self.query._step', 'bert.encoder.layer.4.attention.self.query.input_thresh', 'bert.encoder.layer.4.attention.self.query.output_thresh', 'bert.encoder.layer.4.attention.self.key._step', 'bert.encoder.layer.4.attention.self.key.input_thresh', 'bert.encoder.layer.4.attention.self.key.output_thresh', 'bert.encoder.layer.4.attention.self.value._step', 'bert.encoder.layer.4.attention.self.value.input_thresh', 'bert.encoder.layer.4.attention.output.dense._step', 'bert.encoder.layer.4.attention.output.dense.input_thresh', 'bert.encoder.layer.4.attention.output.dense.output_thresh', 'bert.encoder.layer.4.intermediate.dense._step', 'bert.encoder.layer.4.intermediate.dense.input_thresh', 'bert.encoder.layer.4.output.dense._step', 'bert.encoder.layer.4.output.dense.input_thresh', 'bert.encoder.layer.5.attention.self._step', 'bert.encoder.layer.5.attention.self.COM2_thresh', 'bert.encoder.layer.5.attention.self.COM3_thresh', 'bert.encoder.layer.5.attention.self.COM4_thresh', 'bert.encoder.layer.5.attention.self.query._step', 'bert.encoder.layer.5.attention.self.query.input_thresh', 'bert.encoder.layer.5.attention.self.query.output_thresh', 'bert.encoder.layer.5.attention.self.key._step', 'bert.encoder.layer.5.attention.self.key.input_thresh', 'bert.encoder.layer.5.attention.self.key.output_thresh', 'bert.encoder.layer.5.attention.self.value._step', 'bert.encoder.layer.5.attention.self.value.input_thresh', 'bert.encoder.layer.5.attention.output.dense._step', 'bert.encoder.layer.5.attention.output.dense.input_thresh', 'bert.encoder.layer.5.attention.output.dense.output_thresh', 'bert.encoder.layer.5.intermediate.dense._step', 'bert.encoder.layer.5.intermediate.dense.input_thresh', 'bert.encoder.layer.5.output.dense._step', 'bert.encoder.layer.5.output.dense.input_thresh', 'bert.encoder.layer.6.attention.self._step', 'bert.encoder.layer.6.attention.self.COM2_thresh', 'bert.encoder.layer.6.attention.self.COM3_thresh', 'bert.encoder.layer.6.attention.self.COM4_thresh', 'bert.encoder.layer.6.attention.self.query._step', 'bert.encoder.layer.6.attention.self.query.input_thresh', 'bert.encoder.layer.6.attention.self.query.output_thresh', 'bert.encoder.layer.6.attention.self.key._step', 'bert.encoder.layer.6.attention.self.key.input_thresh', 'bert.encoder.layer.6.attention.self.key.output_thresh', 'bert.encoder.layer.6.attention.self.value._step', 'bert.encoder.layer.6.attention.self.value.input_thresh', 'bert.encoder.layer.6.attention.output.dense._step', 'bert.encoder.layer.6.attention.output.dense.input_thresh', 'bert.encoder.layer.6.attention.output.dense.output_thresh', 'bert.encoder.layer.6.intermediate.dense._step', 'bert.encoder.layer.6.intermediate.dense.input_thresh', 'bert.encoder.layer.6.output.dense._step', 'bert.encoder.layer.6.output.dense.input_thresh', 'bert.encoder.layer.7.attention.self._step', 'bert.encoder.layer.7.attention.self.COM2_thresh', 'bert.encoder.layer.7.attention.self.COM3_thresh', 'bert.encoder.layer.7.attention.self.COM4_thresh', 'bert.encoder.layer.7.attention.self.query._step', 'bert.encoder.layer.7.attention.self.query.input_thresh', 'bert.encoder.layer.7.attention.self.query.output_thresh', 'bert.encoder.layer.7.attention.self.key._step', 'bert.encoder.layer.7.attention.self.key.input_thresh', 'bert.encoder.layer.7.attention.self.key.output_thresh', 'bert.encoder.layer.7.attention.self.value._step', 'bert.encoder.layer.7.attention.self.value.input_thresh', 'bert.encoder.layer.7.attention.output.dense._step', 'bert.encoder.layer.7.attention.output.dense.input_thresh', 'bert.encoder.layer.7.attention.output.dense.output_thresh', 'bert.encoder.layer.7.intermediate.dense._step', 'bert.encoder.layer.7.intermediate.dense.input_thresh', 'bert.encoder.layer.7.output.dense._step', 'bert.encoder.layer.7.output.dense.input_thresh', 'bert.encoder.layer.8.attention.self._step', 'bert.encoder.layer.8.attention.self.COM2_thresh', 'bert.encoder.layer.8.attention.self.COM3_thresh', 'bert.encoder.layer.8.attention.self.COM4_thresh', 'bert.encoder.layer.8.attention.self.query._step', 'bert.encoder.layer.8.attention.self.query.input_thresh', 'bert.encoder.layer.8.attention.self.query.output_thresh', 'bert.encoder.layer.8.attention.self.key._step', 'bert.encoder.layer.8.attention.self.key.input_thresh', 'bert.encoder.layer.8.attention.self.key.output_thresh', 'bert.encoder.layer.8.attention.self.value._step', 'bert.encoder.layer.8.attention.self.value.input_thresh', 'bert.encoder.layer.8.attention.output.dense._step', 'bert.encoder.layer.8.attention.output.dense.input_thresh', 'bert.encoder.layer.8.attention.output.dense.output_thresh', 'bert.encoder.layer.8.intermediate.dense._step', 'bert.encoder.layer.8.intermediate.dense.input_thresh', 'bert.encoder.layer.8.output.dense._step', 'bert.encoder.layer.8.output.dense.input_thresh', 'bert.encoder.layer.9.attention.self._step', 'bert.encoder.layer.9.attention.self.COM2_thresh', 'bert.encoder.layer.9.attention.self.COM3_thresh', 'bert.encoder.layer.9.attention.self.COM4_thresh', 'bert.encoder.layer.9.attention.self.query._step', 'bert.encoder.layer.9.attention.self.query.input_thresh', 'bert.encoder.layer.9.attention.self.query.output_thresh', 'bert.encoder.layer.9.attention.self.key._step', 'bert.encoder.layer.9.attention.self.key.input_thresh', 'bert.encoder.layer.9.attention.self.key.output_thresh', 'bert.encoder.layer.9.attention.self.value._step', 'bert.encoder.layer.9.attention.self.value.input_thresh', 'bert.encoder.layer.9.attention.output.dense._step', 'bert.encoder.layer.9.attention.output.dense.input_thresh', 'bert.encoder.layer.9.attention.output.dense.output_thresh', 'bert.encoder.layer.9.intermediate.dense._step', 'bert.encoder.layer.9.intermediate.dense.input_thresh', 'bert.encoder.layer.9.output.dense._step', 'bert.encoder.layer.9.output.dense.input_thresh', 'bert.encoder.layer.10.attention.self._step', 'bert.encoder.layer.10.attention.self.COM2_thresh', 'bert.encoder.layer.10.attention.self.COM3_thresh', 'bert.encoder.layer.10.attention.self.COM4_thresh', 'bert.encoder.layer.10.attention.self.query._step', 'bert.encoder.layer.10.attention.self.query.input_thresh', 'bert.encoder.layer.10.attention.self.query.output_thresh', 'bert.encoder.layer.10.attention.self.key._step', 'bert.encoder.layer.10.attention.self.key.input_thresh', 'bert.encoder.layer.10.attention.self.key.output_thresh', 'bert.encoder.layer.10.attention.self.value._step', 'bert.encoder.layer.10.attention.self.value.input_thresh', 'bert.encoder.layer.10.attention.output.dense._step', 'bert.encoder.layer.10.attention.output.dense.input_thresh', 'bert.encoder.layer.10.attention.output.dense.output_thresh', 'bert.encoder.layer.10.intermediate.dense._step', 'bert.encoder.layer.10.intermediate.dense.input_thresh', 'bert.encoder.layer.10.output.dense._step', 'bert.encoder.layer.10.output.dense.input_thresh', 'bert.encoder.layer.11.attention.self._step', 'bert.encoder.layer.11.attention.self.COM2_thresh', 'bert.encoder.layer.11.attention.self.COM3_thresh', 'bert.encoder.layer.11.attention.self.COM4_thresh', 'bert.encoder.layer.11.attention.self.query._step', 'bert.encoder.layer.11.attention.self.query.input_thresh', 'bert.encoder.layer.11.attention.self.query.output_thresh', 'bert.encoder.layer.11.attention.self.key._step', 'bert.encoder.layer.11.attention.self.key.input_thresh', 'bert.encoder.layer.11.attention.self.key.output_thresh', 'bert.encoder.layer.11.attention.self.value._step', 'bert.encoder.layer.11.attention.self.value.input_thresh', 'bert.encoder.layer.11.attention.output.dense._step', 'bert.encoder.layer.11.attention.output.dense.input_thresh', 'bert.encoder.layer.11.attention.output.dense.output_thresh', 'bert.encoder.layer.11.intermediate.dense._step', 'bert.encoder.layer.11.intermediate.dense.input_thresh', 'bert.encoder.layer.11.output.dense._step', 'bert.encoder.layer.11.output.dense.input_thresh', 'bert.pooler.dense._step', 'bert.pooler.dense.input_thresh', 'classifier.weight', 'classifier.bias', 'classifier._step', 'classifier.input_thresh']
2021-04-22 14:11:48,647 INFO Weights from pretrained model not used in QuantizedBertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']
name :  / class: QuantizedBertForSequenceClassification
name : bert / class: QuantizedBertModel
name : bert.embeddings / class: QuantizedBertEmbeddings
name : bert.embeddings.word_embeddings / class: QuantizedEmbedding
name : bert.embeddings.position_embeddings / class: QuantizedEmbedding
name : bert.embeddings.token_type_embeddings / class: QuantizedEmbedding
name : bert.embeddings.LayerNorm / class: LayerNorm
name : bert.embeddings.dropout / class: Dropout
name : bert.encoder / class: QuantizedBertEncoder
name : bert.encoder.layer / class: ModuleList
name : bert.encoder.layer.0 / class: QuantizedBertLayer
name : bert.encoder.layer.0.attention / class: QuantizedBertAttention
name : bert.encoder.layer.0.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.0.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.0.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.0.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.0.attention.self.dropout / class: Dropout
name : bert.encoder.layer.0.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.0.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.0.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.0.attention.output.dropout / class: Dropout
name : bert.encoder.layer.0.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.0.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.0.output / class: QuantizedBertOutput
name : bert.encoder.layer.0.output.dense / class: QuantizedLinear
name : bert.encoder.layer.0.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.0.output.dropout / class: Dropout
name : bert.encoder.layer.1 / class: QuantizedBertLayer
name : bert.encoder.layer.1.attention / class: QuantizedBertAttention
name : bert.encoder.layer.1.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.1.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.1.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.1.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.1.attention.self.dropout / class: Dropout
name : bert.encoder.layer.1.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.1.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.1.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.1.attention.output.dropout / class: Dropout
name : bert.encoder.layer.1.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.1.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.1.output / class: QuantizedBertOutput
name : bert.encoder.layer.1.output.dense / class: QuantizedLinear
name : bert.encoder.layer.1.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.1.output.dropout / class: Dropout
name : bert.encoder.layer.2 / class: QuantizedBertLayer
name : bert.encoder.layer.2.attention / class: QuantizedBertAttention
name : bert.encoder.layer.2.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.2.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.2.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.2.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.2.attention.self.dropout / class: Dropout
name : bert.encoder.layer.2.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.2.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.2.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.2.attention.output.dropout / class: Dropout
name : bert.encoder.layer.2.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.2.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.2.output / class: QuantizedBertOutput
name : bert.encoder.layer.2.output.dense / class: QuantizedLinear
name : bert.encoder.layer.2.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.2.output.dropout / class: Dropout
name : bert.encoder.layer.3 / class: QuantizedBertLayer
name : bert.encoder.layer.3.attention / class: QuantizedBertAttention
name : bert.encoder.layer.3.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.3.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.3.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.3.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.3.attention.self.dropout / class: Dropout
name : bert.encoder.layer.3.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.3.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.3.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.3.attention.output.dropout / class: Dropout
name : bert.encoder.layer.3.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.3.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.3.output / class: QuantizedBertOutput
name : bert.encoder.layer.3.output.dense / class: QuantizedLinear
name : bert.encoder.layer.3.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.3.output.dropout / class: Dropout
name : bert.encoder.layer.4 / class: QuantizedBertLayer
name : bert.encoder.layer.4.attention / class: QuantizedBertAttention
name : bert.encoder.layer.4.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.4.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.4.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.4.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.4.attention.self.dropout / class: Dropout
name : bert.encoder.layer.4.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.4.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.4.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.4.attention.output.dropout / class: Dropout
name : bert.encoder.layer.4.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.4.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.4.output / class: QuantizedBertOutput
name : bert.encoder.layer.4.output.dense / class: QuantizedLinear
name : bert.encoder.layer.4.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.4.output.dropout / class: Dropout
name : bert.encoder.layer.5 / class: QuantizedBertLayer
name : bert.encoder.layer.5.attention / class: QuantizedBertAttention
name : bert.encoder.layer.5.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.5.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.5.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.5.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.5.attention.self.dropout / class: Dropout
name : bert.encoder.layer.5.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.5.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.5.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.5.attention.output.dropout / class: Dropout
name : bert.encoder.layer.5.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.5.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.5.output / class: QuantizedBertOutput
name : bert.encoder.layer.5.output.dense / class: QuantizedLinear
name : bert.encoder.layer.5.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.5.output.dropout / class: Dropout
name : bert.encoder.layer.6 / class: QuantizedBertLayer
name : bert.encoder.layer.6.attention / class: QuantizedBertAttention
name : bert.encoder.layer.6.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.6.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.6.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.6.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.6.attention.self.dropout / class: Dropout
name : bert.encoder.layer.6.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.6.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.6.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.6.attention.output.dropout / class: Dropout
name : bert.encoder.layer.6.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.6.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.6.output / class: QuantizedBertOutput
name : bert.encoder.layer.6.output.dense / class: QuantizedLinear
name : bert.encoder.layer.6.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.6.output.dropout / class: Dropout
name : bert.encoder.layer.7 / class: QuantizedBertLayer
name : bert.encoder.layer.7.attention / class: QuantizedBertAttention
name : bert.encoder.layer.7.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.7.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.7.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.7.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.7.attention.self.dropout / class: Dropout
name : bert.encoder.layer.7.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.7.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.7.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.7.attention.output.dropout / class: Dropout
name : bert.encoder.layer.7.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.7.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.7.output / class: QuantizedBertOutput
name : bert.encoder.layer.7.output.dense / class: QuantizedLinear
name : bert.encoder.layer.7.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.7.output.dropout / class: Dropout
name : bert.encoder.layer.8 / class: QuantizedBertLayer
name : bert.encoder.layer.8.attention / class: QuantizedBertAttention
name : bert.encoder.layer.8.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.8.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.8.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.8.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.8.attention.self.dropout / class: Dropout
name : bert.encoder.layer.8.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.8.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.8.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.8.attention.output.dropout / class: Dropout
name : bert.encoder.layer.8.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.8.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.8.output / class: QuantizedBertOutput
name : bert.encoder.layer.8.output.dense / class: QuantizedLinear
name : bert.encoder.layer.8.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.8.output.dropout / class: Dropout
name : bert.encoder.layer.9 / class: QuantizedBertLayer
name : bert.encoder.layer.9.attention / class: QuantizedBertAttention
name : bert.encoder.layer.9.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.9.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.9.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.9.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.9.attention.self.dropout / class: Dropout
name : bert.encoder.layer.9.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.9.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.9.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.9.attention.output.dropout / class: Dropout
name : bert.encoder.layer.9.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.9.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.9.output / class: QuantizedBertOutput
name : bert.encoder.layer.9.output.dense / class: QuantizedLinear
name : bert.encoder.layer.9.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.9.output.dropout / class: Dropout
name : bert.encoder.layer.10 / class: QuantizedBertLayer
name : bert.encoder.layer.10.attention / class: QuantizedBertAttention
name : bert.encoder.layer.10.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.10.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.10.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.10.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.10.attention.self.dropout / class: Dropout
name : bert.encoder.layer.10.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.10.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.10.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.10.attention.output.dropout / class: Dropout
name : bert.encoder.layer.10.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.10.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.10.output / class: QuantizedBertOutput
name : bert.encoder.layer.10.output.dense / class: QuantizedLinear
name : bert.encoder.layer.10.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.10.output.dropout / class: Dropout
name : bert.encoder.layer.11 / class: QuantizedBertLayer
name : bert.encoder.layer.11.attention / class: QuantizedBertAttention
name : bert.encoder.layer.11.attention.self / class: QuantizedBertSelfAttention
name : bert.encoder.layer.11.attention.self.query / class: QuantizedLinear
name : bert.encoder.layer.11.attention.self.key / class: QuantizedLinear
name : bert.encoder.layer.11.attention.self.value / class: QuantizedLinear
name : bert.encoder.layer.11.attention.self.dropout / class: Dropout
name : bert.encoder.layer.11.attention.output / class: QuantizedBertSelfOutput
name : bert.encoder.layer.11.attention.output.dense / class: QuantizedLinear
name : bert.encoder.layer.11.attention.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.11.attention.output.dropout / class: Dropout
name : bert.encoder.layer.11.intermediate / class: QuantizedBertIntermediate
name : bert.encoder.layer.11.intermediate.dense / class: QuantizedLinear
name : bert.encoder.layer.11.output / class: QuantizedBertOutput
name : bert.encoder.layer.11.output.dense / class: QuantizedLinear
name : bert.encoder.layer.11.output.LayerNorm / class: LayerNorm
name : bert.encoder.layer.11.output.dropout / class: Dropout
name : bert.pooler / class: QuantizedBertPooler
name : bert.pooler.dense / class: QuantizedLinear
name : bert.pooler.activation / class: Tanh
name : dropout / class: Dropout
name : classifier / class: QuantizedLinear
> /home/hs402/nlp-architect/nlp_architect/models/transformers/sequence_classification.py(117)__init__()
-> if not self.recorder.wandb_off:
(Pdb) 
Traceback (most recent call last):
  File "/home/hs402/anaconda3/envs/nlp/bin/nlp-train", line 7, in <module>
    exec(compile(f.read(), __file__, 'exec'))
  File "/home/hs402/nlp-architect/nlp_architect/nlp-train", line 5, in <module>
    nlp_train_cli()
  File "/home/hs402/nlp-architect/nlp_architect/cli/__init__.py", line 45, in nlp_train_cli
    args.func(args)
  File "/home/hs402/nlp-architect/nlp_architect/procedures/transformers/glue.py", line 47, in run_procedure
    do_training(args)
  File "/home/hs402/nlp-architect/nlp_architect/procedures/transformers/glue.py", line 179, in do_training
    freeze_bert=args.freeze_bert
  File "/home/hs402/nlp-architect/nlp_architect/models/transformers/sequence_classification.py", line 117, in __init__
    if not self.recorder.wandb_off:
  File "/home/hs402/nlp-architect/nlp_architect/models/transformers/sequence_classification.py", line 117, in __init__
    if not self.recorder.wandb_off:
  File "/home/hs402/anaconda3/envs/nlp/lib/python3.7/bdb.py", line 88, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/hs402/anaconda3/envs/nlp/lib/python3.7/bdb.py", line 113, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit
(nlp) ]0;hs402@AIHA-Server1: ~/nlp-architect/skt1_scripts[01;32mhs402@AIHA-Server1[00m:[01;34m~/nlp-architect/skt1_scripts[00m$ exit
exit

Script done on 2021-04-22 14:12:08+0900
